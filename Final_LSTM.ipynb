{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k3vSLSOXiYpM"
   },
   "outputs": [],
   "source": [
    "#https://github.com/Pawandeep-prog/chatbot\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.layers import Input,Embedding,LSTM,Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import tensorflow as tf\n",
    "from  sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhSzBA9clZ8H",
    "outputId": "96a3f59f-58b5-4144-acb6-cb073c00abf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thích đánh lộn không? __eou__ Ngon nhà vô __eou__\\n', 'Solo yasua không __eou__ Chấp lun 2 mạng đầu __eou__\\n', 'Mai đi picnic không? __eou__ Mai bận học rồi __eou__\\n', 'Mai học ca mấy vậy? __eou__ Mai học ca 3 __eou__\\n', 'Còn tiền không? __eou__ Còn chết liền __eou__\\n']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "datapath = glob.glob(os.path.join(path,\"data/*.txt\"))\n",
    "fulldata = []\n",
    "for i in datapath:\n",
    "    with open(i,'r',encoding='utf-8') as f:\n",
    "#     lines = [i.strip() for i in f.readlines()]\n",
    "        lines = f.readlines()\n",
    "    for j in lines:\n",
    "        fulldata.append(j)\n",
    "print(fulldata[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yeaSNjnl6WO",
    "outputId": "5b09faa2-a857-469c-f3a6-3f293d81ed82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5855\n",
      "[' Ngon nhà vô ', ' Chấp lun 2 mạng đầu ', ' Mai bận học rồi ', ' Mai học ca 3 ', ' Còn chết liền ']\n"
     ]
    }
   ],
   "source": [
    "data = [i.split('__eou__') for i in fulldata]\n",
    "data_question = [i[0] for i in data]\n",
    "data_answer = [i[1] for i in data]\n",
    "print(len(data_question))\n",
    "print(data_answer[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EwMzy6CJF9If"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text_ = text.lower()\n",
    "  text_ = re.sub(r'([^\\s\\w]|_)+', '', text_)\n",
    "  return text_.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pC4UA10RGSey"
   },
   "outputs": [],
   "source": [
    "#Làm sạch text\n",
    "for i in range(len(data_question)):\n",
    "  data_question[i] =clean_text(data_question[i])\n",
    "\n",
    "for i in range(len(data_answer)):\n",
    "  data_answer[i] = clean_text(data_answer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V5nN_64zMuWC"
   },
   "outputs": [],
   "source": [
    "# đếm số lần xuất hiện của 1 từ trong data_question và data_answer\n",
    "word2count = {}\n",
    "\n",
    "for i in data_question:\n",
    "  for word in i.split():\n",
    "    if word not in word2count:\n",
    "      word2count[word] = 1\n",
    "    else:\n",
    "      word2count[word] +=1\n",
    "\n",
    "for i in data_answer:\n",
    "  for word in i.split():\n",
    "    if word not in word2count:\n",
    "      word2count[word] = 1\n",
    "    else:\n",
    "      word2count[word] +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KTRzMORFjqqP"
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "word_index = 0\n",
    "\n",
    "for word, count in word2count.items():\n",
    "    vocab[word] = word_index\n",
    "    word_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<begin> ngon nhà vô <end>', '<begin> chấp lun 2 mạng đầu <end>', '<begin> mai bận học rồi <end>', '<begin> mai học ca 3 <end>', '<begin> còn chết liền <end>']\n"
     ]
    }
   ],
   "source": [
    "# Gắn <begin> và <end>\n",
    "for i in range(len(data_answer)):\n",
    "  data_answer[i] = '<begin> ' + data_answer[i] + ' <end>'\n",
    "print(data_answer[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<pad>','<end>','<begin>','<out>']\n",
    "x = len(vocab)\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1\n",
    "    \n",
    "vocab['ạ'] = vocab['<pad>']\n",
    "vocab['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_vocab = {w:v for v,w in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRDno9wxR5e2",
    "outputId": "956dac78-6b72-4eea-fdb0-245b59500ec7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5855, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inp = []\n",
    "for i in data_question:\n",
    "  lst = []\n",
    "  for word in i.split():\n",
    "    if word not in vocab:\n",
    "      lst.append(vocab['<out>'])\n",
    "    else:\n",
    "      lst.append(vocab[word])\n",
    "  encoder_inp.append(lst)\n",
    "\n",
    "encoder_inp = pad_sequences(encoder_inp,13, padding= 'post', truncating= 'post')\n",
    "encoder_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXknjM8gl_hC",
    "outputId": "b08a93e2-d73d-4222-f579-faf9e5af5753"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5855, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inp = []\n",
    "for i in data_answer:\n",
    "  lst = []\n",
    "  for word in i.split():\n",
    "    if word not in vocab:\n",
    "      lst.append(vocab['<out>'])\n",
    "    else:\n",
    "      lst.append(vocab[word])\n",
    "  decoder_inp.append(lst)\n",
    "\n",
    "decoder_inp = pad_sequences(decoder_inp,13, padding= 'post', truncating= 'post')\n",
    "decoder_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zK1L9ThCmQqI",
    "outputId": "6024d602-7886-4efb-a040-e3fee3d9fc4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5855, 13)\n",
      "(5855, 13, 3549)\n"
     ]
    }
   ],
   "source": [
    "decoder_final = []\n",
    "for i in decoder_inp:\n",
    "    decoder_final.append(i[1:]) \n",
    "\n",
    "decoder_final = pad_sequences(decoder_final,13, padding= 'post', truncating= 'post')\n",
    "print(decoder_final.shape)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "decoder_final= to_categorical(decoder_final, len(vocab))\n",
    "print(decoder_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36vptEPSmP91"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtCCwzXbwcfq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tT-Qz_33x3jl",
    "outputId": "324f3231-1dc1-4be0-bbb7-57beede51f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 13, 50)       177500      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 13, 400), (N 721600      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 13, 400), (N 721600      embedding[1][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 13, 3549)     1423149     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,043,849\n",
      "Trainable params: 3,043,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import Dense,Conv1D,MaxPooling1D,Flatten,Embedding\n",
    "\n",
    "enc_inp = Input(shape = (13,))\n",
    "dec_inp = Input(shape = (13,))\n",
    "vocab_size=len(vocab)\n",
    "\n",
    "model = Sequential()\n",
    "embed = Embedding(vocab_size+1,output_dim=50,input_length = 13,trainable=True)\n",
    "\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = LSTM(400,return_sequences=True,return_state=True)\n",
    "enc_op, h, c = enc_lstm(enc_embed)\n",
    "enc_states = [h, c]\n",
    "\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "dense = Dense(vocab_size, activation='softmax')\n",
    "\n",
    "dense_op = dense(dec_op)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], dense_op)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PdnOaMdwyZb4",
    "outputId": "f8fc82a2-323a-4a9b-de00-99b7dfa89d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "183/183 [==============================] - 53s 288ms/step - loss: 4.0212 - accuracy: 0.4431\n",
      "Epoch 2/50\n",
      "183/183 [==============================] - 53s 291ms/step - loss: 3.4400 - accuracy: 0.4865\n",
      "Epoch 3/50\n",
      "183/183 [==============================] - 54s 293ms/step - loss: 3.3663 - accuracy: 0.4883\n",
      "Epoch 4/50\n",
      "183/183 [==============================] - 58s 319ms/step - loss: 3.2955 - accuracy: 0.4922\n",
      "Epoch 5/50\n",
      "183/183 [==============================] - 60s 330ms/step - loss: 3.2162 - accuracy: 0.4964\n",
      "Epoch 6/50\n",
      "183/183 [==============================] - 63s 346ms/step - loss: 3.1392 - accuracy: 0.5014\n",
      "Epoch 7/50\n",
      "183/183 [==============================] - 60s 330ms/step - loss: 3.0717 - accuracy: 0.5054\n",
      "Epoch 8/50\n",
      "183/183 [==============================] - 68s 372ms/step - loss: 3.0007 - accuracy: 0.5106\n",
      "Epoch 9/50\n",
      "183/183 [==============================] - 63s 344ms/step - loss: 2.9213 - accuracy: 0.5167\n",
      "Epoch 10/50\n",
      "183/183 [==============================] - 65s 357ms/step - loss: 2.8448 - accuracy: 0.5224\n",
      "Epoch 11/50\n",
      "183/183 [==============================] - 64s 351ms/step - loss: 2.7726 - accuracy: 0.5275\n",
      "Epoch 12/50\n",
      "183/183 [==============================] - 57s 310ms/step - loss: 2.7007 - accuracy: 0.5329\n",
      "Epoch 13/50\n",
      "183/183 [==============================] - 58s 319ms/step - loss: 2.6303 - accuracy: 0.5384\n",
      "Epoch 14/50\n",
      "183/183 [==============================] - 64s 347ms/step - loss: 2.5621 - accuracy: 0.5443\n",
      "Epoch 15/50\n",
      "183/183 [==============================] - 61s 334ms/step - loss: 2.4937 - accuracy: 0.5502\n",
      "Epoch 16/50\n",
      "183/183 [==============================] - 56s 309ms/step - loss: 2.4256 - accuracy: 0.5565\n",
      "Epoch 17/50\n",
      "183/183 [==============================] - 59s 325ms/step - loss: 2.3618 - accuracy: 0.5634\n",
      "Epoch 18/50\n",
      "183/183 [==============================] - 62s 337ms/step - loss: 2.2962 - accuracy: 0.5711\n",
      "Epoch 19/50\n",
      "183/183 [==============================] - 59s 324ms/step - loss: 2.2302 - accuracy: 0.5798\n",
      "Epoch 20/50\n",
      "183/183 [==============================] - 58s 315ms/step - loss: 2.1668 - accuracy: 0.5885\n",
      "Epoch 21/50\n",
      "183/183 [==============================] - 62s 339ms/step - loss: 2.1043 - accuracy: 0.5976\n",
      "Epoch 22/50\n",
      "183/183 [==============================] - 58s 317ms/step - loss: 2.0469 - accuracy: 0.6049\n",
      "Epoch 23/50\n",
      "183/183 [==============================] - 59s 324ms/step - loss: 1.9858 - accuracy: 0.6133\n",
      "Epoch 24/50\n",
      "183/183 [==============================] - 58s 319ms/step - loss: 1.9296 - accuracy: 0.6221\n",
      "Epoch 25/50\n",
      "183/183 [==============================] - 58s 318ms/step - loss: 1.8721 - accuracy: 0.6311\n",
      "Epoch 26/50\n",
      "183/183 [==============================] - 58s 317ms/step - loss: 1.8159 - accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "183/183 [==============================] - 59s 322ms/step - loss: 1.7641 - accuracy: 0.6498\n",
      "Epoch 28/50\n",
      "183/183 [==============================] - 55s 302ms/step - loss: 1.7102 - accuracy: 0.6576\n",
      "Epoch 29/50\n",
      "183/183 [==============================] - 61s 335ms/step - loss: 1.6573 - accuracy: 0.6666\n",
      "Epoch 30/50\n",
      "183/183 [==============================] - 57s 314ms/step - loss: 1.6056 - accuracy: 0.6744\n",
      "Epoch 31/50\n",
      "183/183 [==============================] - 58s 319ms/step - loss: 1.5560 - accuracy: 0.6838\n",
      "Epoch 32/50\n",
      "183/183 [==============================] - 60s 330ms/step - loss: 1.5088 - accuracy: 0.6909\n",
      "Epoch 33/50\n",
      "183/183 [==============================] - 60s 328ms/step - loss: 1.4632 - accuracy: 0.6994\n",
      "Epoch 34/50\n",
      "183/183 [==============================] - 61s 331ms/step - loss: 1.4168 - accuracy: 0.7085\n",
      "Epoch 35/50\n",
      "183/183 [==============================] - 57s 314ms/step - loss: 1.3719 - accuracy: 0.7184\n",
      "Epoch 36/50\n",
      "183/183 [==============================] - 60s 330ms/step - loss: 1.3287 - accuracy: 0.7254\n",
      "Epoch 37/50\n",
      "183/183 [==============================] - 55s 303ms/step - loss: 1.2832 - accuracy: 0.7350\n",
      "Epoch 38/50\n",
      "183/183 [==============================] - 55s 302ms/step - loss: 1.2439 - accuracy: 0.7423\n",
      "Epoch 39/50\n",
      "183/183 [==============================] - 60s 326ms/step - loss: 1.2047 - accuracy: 0.7498\n",
      "Epoch 40/50\n",
      "183/183 [==============================] - 59s 323ms/step - loss: 1.1648 - accuracy: 0.7570\n",
      "Epoch 41/50\n",
      "183/183 [==============================] - 59s 321ms/step - loss: 1.1240 - accuracy: 0.7663\n",
      "Epoch 42/50\n",
      "183/183 [==============================] - 58s 319ms/step - loss: 1.0850 - accuracy: 0.7728\n",
      "Epoch 43/50\n",
      "183/183 [==============================] - 56s 307ms/step - loss: 1.0478 - accuracy: 0.7811\n",
      "Epoch 44/50\n",
      "183/183 [==============================] - 58s 319ms/step - loss: 1.0102 - accuracy: 0.7878\n",
      "Epoch 45/50\n",
      "183/183 [==============================] - 59s 320ms/step - loss: 0.9751 - accuracy: 0.7943\n",
      "Epoch 46/50\n",
      "183/183 [==============================] - 59s 325ms/step - loss: 0.9391 - accuracy: 0.8031\n",
      "Epoch 47/50\n",
      "183/183 [==============================] - 57s 311ms/step - loss: 0.9045 - accuracy: 0.8096\n",
      "Epoch 48/50\n",
      "183/183 [==============================] - 60s 326ms/step - loss: 0.8716 - accuracy: 0.8154\n",
      "Epoch 49/50\n",
      "183/183 [==============================] - 58s 318ms/step - loss: 0.8393 - accuracy: 0.8212\n",
      "Epoch 50/50\n",
      "183/183 [==============================] - 58s 315ms/step - loss: 0.8051 - accuracy: 0.8282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e8de23af0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_inp, decoder_inp],decoder_final,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "P-oacCIuQV1J"
   },
   "outputs": [],
   "source": [
    "## Seq2Seq\n",
    "#Encoder model\n",
    "enc_model = Model([enc_inp], enc_states)\n",
    "\n",
    "#Decoder model\n",
    "decoder_state_input_h = Input(shape=(400, ))\n",
    "decoder_state_input_c = Input(shape=(400, ))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "dec_model = Model([dec_inp] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mesfzJbZQe_6",
    "outputId": "db26696c-1d5c-46e9-d5df-7ed10b90115a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: bạn học gì\n",
      "Bot:  minh hoc công nghê thông tin \n",
      "=====================================\n",
      "You: bạn học ở đâu\n",
      "Bot:  minh hoc công nghê thông tin \n",
      "=====================================\n",
      "You: crush ai khôn\n",
      "Bot:  có chứ \n",
      "=====================================\n",
      "You: cậu có thể nói gì đó tốt hơn không\n",
      "Bot:  dạ còn ạ \n",
      "=====================================\n",
      "You: đi đâu đấy\n",
      "Bot:  đi về nhà \n",
      "=====================================\n",
      "You: có thích đi du lịch không\n",
      "Bot:  ok anh \n",
      "=====================================\n",
      "You: bạn thích đi du lịch ở đâu\n",
      "Bot:  minh thich lord of the ring \n",
      "=====================================\n",
      "You: bye\n",
      "Bot:  đi về nhà \n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "inv_vocab = {w:v for v,w in vocab.items()}\n",
    "prepro1 = \"\"\n",
    "while prepro1 != 'bye':\n",
    "    prepro1 = str(input(\"You: \"))\n",
    "\n",
    "    prepro1 = clean_text(prepro1)\n",
    "\n",
    "    prepro = [prepro1]\n",
    "\n",
    "    txt = []\n",
    "\n",
    "    for x in prepro:\n",
    "        lst = []\n",
    "        for y in x.split():\n",
    "            try:\n",
    "                lst.append(vocab[y])\n",
    "            except:\n",
    "                lst.append(vocab['<out>'])\n",
    "    txt.append(lst)\n",
    "\n",
    "    txt = pad_sequences(txt, 13, padding= 'post')\n",
    "\n",
    "    stat = enc_model.predict(txt)\n",
    "\n",
    "    empty_target_seq = np.zeros( (1,1) )\n",
    "    empty_target_seq[0, 0] = vocab['<begin>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq]+ stat)\n",
    "\n",
    "        decoder_concat_input = dense(dec_outputs)\n",
    "\n",
    "        sampled_word_index = np.argmax(decoder_concat_input[0,-1,:])\n",
    "\n",
    "        sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "        if sampled_word != '<end> ':\n",
    "            decoded_translation += sampled_word\n",
    "    \n",
    "        if sampled_word == '<end> ' or len(decoded_translation.split()) > 15:\n",
    "            stop_condition = True\n",
    "\n",
    "        empty_target_seq = np.zeros( (1, 1) )\n",
    "        empty_target_seq[0, 0] = sampled_word_index\n",
    "\n",
    "        stat = [h,c]\n",
    "\n",
    "    print(\"Bot: \", decoded_translation)\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final_CNN_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
